{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 6: Clustering and Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you'll practice different text clustering methods. A dataset has been prepared for you:\n",
    "- `hw6_train.csv`: This file contains a list of documents. It's used for training models\n",
    "- `hw6_test`: This file contains a list of documents and their ground-truth labels (4 lables: 1,2,3,7). It's used for external evaluation. \n",
    "\n",
    "|Text| Label|\n",
    "|----|-------|\n",
    "|paraglider collides with hot air balloon ... | 1|\n",
    "|faa issues fire warning for lithium ... | 2|\n",
    "| .... |...|\n",
    "\n",
    "Sample outputs have been provided to you. Due to randomness, you may not get the same result as shown here. Your taget is to achieve about 70% F1 for the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: K-Mean Clustering \n",
    "\n",
    "Define a function `cluster_kmean(train_text, test_text, text_label)` as follows:\n",
    "- Take three inputs: \n",
    "    - `train_text` is a list of documents for traing \n",
    "    - `test_text` is a list of documents for test\n",
    "    - `test_label` is the labels corresponding to documents in `test_text` \n",
    "- First generate `TFIDF` weights. You need to decide appropriate values for parameters such as `stopwords` and `min_df`:\n",
    "    - Keep or remove stopwords? Customized stop words? \n",
    "    - Set appropriate `min_df` to filter infrequent words\n",
    "- Use `KMeans` to cluster documents in `train_text` into 4 clusters. Here you need to decide the following parameters:\n",
    "    \n",
    "    - Distance measure: `cosine similarity`  or `Euclidean distance`? Pick the one which gives you better performance.  \n",
    "    - When clustering, be sure to  use sufficient iterations with different initial centroids to make sure clustering converge.\n",
    "- Test the clustering model performance using `test_label` as follows: \n",
    "  - Predict the cluster ID for each document in `test_text`.\n",
    "  - Apply `majority vote` rule to dynamically map the predicted cluster IDs to `test_label`. Note, you'd better not hardcode the mapping, because cluster IDs may be assigned differently in each run. (hint: if you use pandas, look for `idxmax` function).\n",
    "  - print out the classification report for the test subset \n",
    "  \n",
    "  \n",
    "- This function has no return. Print out the classification report. \n",
    "\n",
    "\n",
    "- Briefly discuss:\n",
    "    - Which distance measure is better and why it is better. \n",
    "    - Could you assign a meaningful name to each cluster? Discuss how you interpret each cluster.\n",
    "- Write your analysis in a pdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your import statement\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster import KMeansClusterer,cosine_distance,euclidean_distance\n",
    "from sklearn import mixture\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Would you rather get a gift that you knew what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is the internet ruining people's ability to co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Permanganate?\\nSuppose permanganate was used t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If Rock-n-Roll is really the work of the devil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Has anyone purchased software to watch TV on y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Would you rather get a gift that you knew what...\n",
       "1  Is the internet ruining people's ability to co...\n",
       "2  Permanganate?\\nSuppose permanganate was used t...\n",
       "3  If Rock-n-Roll is really the work of the devil...\n",
       "4  Has anyone purchased software to watch TV on y..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"hw6_train.csv\")\n",
    "train_text=train[\"text\"]\n",
    "\n",
    "test = pd.read_csv(\"hw6_test.csv\")\n",
    "test_label = test[\"label\"]\n",
    "test_text = test[\"text\"]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_kmean(train_text, test_text, test_label):\n",
    "    tfidf_vect = TfidfVectorizer(stop_words=\"english\",\\\n",
    "                             min_df=3) \n",
    "    dtm= tfidf_vect.fit_transform(train_text)\n",
    "    \n",
    "    num_clusters=4\n",
    "    clusterer = KMeansClusterer(num_clusters,cosine_distance, \\\n",
    "                            repeats=20)\n",
    "    clusters = clusterer.cluster(dtm.toarray(), \\\n",
    "                             assign_clusters=True)\n",
    "    centroids=np.array(clusterer.means())\n",
    "    sorted_centroids = centroids.argsort()[:, ::-1] \n",
    "    voc_lookup= tfidf_vect.get_feature_names()\n",
    "    test_dtm = tfidf_vect.transform(test_text)\n",
    "    predicted = [clusterer.classify(v) for v in test_dtm.toarray()]\n",
    "    new_p=pd.DataFrame({'Original':test_label,'Predicted':predicted})\n",
    "    new_p=new_p.groupby('Predicted')\n",
    "    new_p1=new_p['Original'].apply(lambda x : x.value_counts().idxmax())\n",
    "    cluster_d={}\n",
    "    for i in range(0,new_p1.shape[0]):\n",
    "        cluster_d[i] = new_p1[i]\n",
    "    predicted_target=[cluster_d[i] for i in predicted]\n",
    "    print(metrics.classification_report\\\n",
    "           (test_label,predicted_target))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.70      0.76       332\n",
      "           2       0.90      0.68      0.77       314\n",
      "           3       0.68      0.88      0.77       355\n",
      "           7       0.69      0.77      0.73       273\n",
      "\n",
      "    accuracy                           0.76      1274\n",
      "   macro avg       0.78      0.75      0.76      1274\n",
      "weighted avg       0.78      0.76      0.76      1274\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Junai\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cluster_kmean(train_text, test_text, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.69      0.76       332\n",
      "           2       0.91      0.68      0.78       314\n",
      "           3       0.67      0.88      0.76       355\n",
      "           7       0.70      0.77      0.73       273\n",
      "\n",
      "    accuracy                           0.76      1274\n",
      "   macro avg       0.78      0.76      0.76      1274\n",
      "weighted avg       0.78      0.76      0.76      1274\n",
      "\n",
      "TfidfVectorizer(min_df=3, stop_words='english')\n"
     ]
    }
   ],
   "source": [
    "cluster_kmean(train_text, test_text, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Clustering by Gaussian Mixture Model\n",
    "\n",
    "In this task, you'll re-do the clustering using a Gaussian Mixture Model. Call this function  `cluster_gmm(train_text, test_text, text_label)`. \n",
    "\n",
    "You may take a subset from the data to do GMM because it can take a lot of time. \n",
    "\n",
    "Write your analysis on the following:\n",
    "- How did you pick the parameters such as the number of clusters, variance type etc.?\n",
    "- Compare to Kmeans in Q1, do you achieve better preformance by GMM? \n",
    "\n",
    "- Note, like KMean, be sure to use different initial means (i.e. `n_init` parameter) when fitting the model to achieve the model stability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_cluster(train_text):\n",
    "    train_text[:5:]\n",
    "    tfidf_vect = TfidfVectorizer(stop_words=\"english\",\\\n",
    "                             min_df=3) \n",
    "    dtm= tfidf_vect.fit_transform(train_text)\n",
    "    lowest_bic = np.infty   # initial BIC is set to infinity\n",
    "    best_gmm = None\n",
    "    n_components_range = range(2,5) \n",
    "    cv_types = ['spherical', 'tied', 'diag']\n",
    "    for cvtype in cv_types:\n",
    "        for n_components in n_components_range:\n",
    "            gmm = mixture.GaussianMixture(n_components=n_components,\n",
    "                                      covariance_type=cvtype, random_state=42)\n",
    "            gmm.fit(dtm.toarray())\n",
    "            bic = gmm.bic(dtm.toarray())\n",
    "            if bic < lowest_bic:  # save the model with lowest BIC sofar\n",
    "                lowest_bic = bic\n",
    "                best_gmm = gmm\n",
    "\n",
    "    print (lowest_bic,best_gmm)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_gmm(train_text, test_text, test_label):\n",
    "    tfidf_vect = TfidfVectorizer(stop_words=\"english\",\\\n",
    "                             min_df=6)\n",
    "    dtm= tfidf_vect.fit_transform(train_text)\n",
    "    test_dtm = tfidf_vect.transform(test_text)\n",
    "    a=mixture.GaussianMixture(covariance_type='diag',n_init=20, n_components=4, random_state=42)\n",
    "    gmm =a.fit(dtm.toarray())\n",
    "    predicted=gmm.predict(test_dtm.toarray())\n",
    "    new_p=pd.DataFrame({'Original':test_label,'Predicted':predicted})\n",
    "    new_p=new_p.groupby('Predicted')\n",
    "    new_p1=new_p['Original'].apply(lambda x : x.value_counts().idxmax())\n",
    "    cluster_d={}\n",
    "    for i in range(0,new_p1.shape[0]):\n",
    "        cluster_d[i] = new_p1[i]\n",
    "    predicted_target=[cluster_d[i] for i in predicted]\n",
    "    print(metrics.classification_report\\\n",
    "           (test_label,predicted_target))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.69      0.71       332\n",
      "           2       0.56      0.86      0.68       314\n",
      "           3       0.79      0.73      0.76       355\n",
      "           7       0.83      0.48      0.61       273\n",
      "\n",
      "    accuracy                           0.70      1274\n",
      "   macro avg       0.73      0.69      0.69      1274\n",
      "weighted avg       0.73      0.70      0.69      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_gmm(train_text, test_text, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: Clustering by LDA \n",
    "\n",
    "In this task, you'll re-do the clustering using LDA. Call this function `cluster_lda(train_text, test_text, text_label)`. \n",
    "\n",
    "However, since LDA returns topic mixture for each document, you `assign the topic with highest probability to each test document`, and then measure the performance as in Q1\n",
    "\n",
    "In addition, within the function, please print out the top 30 words for each topic\n",
    "\n",
    "Finally, please analyze the following:\n",
    "- Based on the top words of each topic, could you assign a meaningful name to each topic?\n",
    "- Although the test subset shows there are 4 clusters, without this information, how do you choose the number of topics? \n",
    "- Does your LDA model achieve better performance than KMeans or GMM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_lda(train_text, test_text, test_label):\n",
    "    tfidf_vect = CountVectorizer(stop_words=\"english\",\\\n",
    "                             min_df=4) \n",
    "    dtm= tfidf_vect.fit_transform(train_text)\n",
    "    test_dtm = tfidf_vect.transform(test_text)\n",
    "    tf_feature_names = tfidf_vect.get_feature_names_out()\n",
    "    num_cluster=4\n",
    "    lda=LatentDirichletAllocation(n_components=num_cluster, \\\n",
    "                                max_iter=40,verbose=1,\n",
    "                                evaluate_every=1, n_jobs=1,\n",
    "                                random_state=1).fit(dtm)\n",
    "    top_words=20\n",
    "    for topic_idx,topic in enumerate (lda.components_):\n",
    "        print ('Topic %d :'% (topic_idx))\n",
    "        words=[(tf_feature_names[i],'%.2f'%topic[i]) \\\n",
    "           for i in topic.argsort()[::-1][0:top_words]]\n",
    "        print(words)\n",
    "        print(\"\\n\")\n",
    "    id2word={idx:w for idx, w in \\\n",
    "         enumerate(tfidf_vect.get_feature_names())}\n",
    "    corpus = gensim.matutils.Sparse2Corpus(dtm, \\\n",
    "                            documents_columns=False)\n",
    "    dictionary = corpora.Dictionary.from_corpus(corpus, \\\n",
    "                            id2word=id2word)\n",
    "    ldamodel = gensim.models.\\\n",
    "    ldamodel.LdaModel(corpus, num_topics = num_cluster, \\\n",
    "                            id2word=id2word, \\\n",
    "                            iterations=28)\n",
    "    test_corpus = gensim.matutils.Sparse2Corpus(test_dtm, \\\n",
    "                    documents_columns=False)\n",
    "    predict = ldamodel.get_document_topics(test_corpus)\n",
    "    predicted=  []\n",
    "    k = list(predict)\n",
    "    for i in k:\n",
    "        predicted.append(max(i,key=lambda item:item[1])[0])\n",
    "    new_p=pd.DataFrame({'Original':test_label,'Predicted':predicted})\n",
    "    new_p=new_p.groupby('Predicted')\n",
    "    new_p1=new_p['Original'].apply(lambda x : x.value_counts().idxmax())\n",
    "    cluster_d={}\n",
    "    for i in range(0,new_p1.shape[0]):\n",
    "        cluster_d[i] = new_p1[i]\n",
    "    predicted_target=[cluster_d[i] for i in predicted]\n",
    "    print(metrics.classification_report\\\n",
    "           (test_label,predicted_target))\n",
    "    \n",
    "            \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    # add your code here\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 40, perplexity: 3744.8238\n",
      "iteration: 2 of max_iter: 40, perplexity: 3495.1870\n",
      "iteration: 3 of max_iter: 40, perplexity: 3306.9531\n",
      "iteration: 4 of max_iter: 40, perplexity: 3160.2251\n",
      "iteration: 5 of max_iter: 40, perplexity: 3050.6756\n",
      "iteration: 6 of max_iter: 40, perplexity: 2964.8248\n",
      "iteration: 7 of max_iter: 40, perplexity: 2904.6078\n",
      "iteration: 8 of max_iter: 40, perplexity: 2862.7297\n",
      "iteration: 9 of max_iter: 40, perplexity: 2834.3298\n",
      "iteration: 10 of max_iter: 40, perplexity: 2814.5958\n",
      "iteration: 11 of max_iter: 40, perplexity: 2800.6554\n",
      "iteration: 12 of max_iter: 40, perplexity: 2789.3890\n",
      "iteration: 13 of max_iter: 40, perplexity: 2780.1794\n",
      "iteration: 14 of max_iter: 40, perplexity: 2772.7972\n",
      "iteration: 15 of max_iter: 40, perplexity: 2766.3616\n",
      "iteration: 16 of max_iter: 40, perplexity: 2761.0165\n",
      "iteration: 17 of max_iter: 40, perplexity: 2756.3925\n",
      "iteration: 18 of max_iter: 40, perplexity: 2752.1355\n",
      "iteration: 19 of max_iter: 40, perplexity: 2748.0342\n",
      "iteration: 20 of max_iter: 40, perplexity: 2743.7933\n",
      "iteration: 21 of max_iter: 40, perplexity: 2739.9207\n",
      "iteration: 22 of max_iter: 40, perplexity: 2736.8511\n",
      "iteration: 23 of max_iter: 40, perplexity: 2734.2854\n",
      "iteration: 24 of max_iter: 40, perplexity: 2732.2559\n",
      "iteration: 25 of max_iter: 40, perplexity: 2730.3677\n",
      "iteration: 26 of max_iter: 40, perplexity: 2728.5721\n",
      "iteration: 27 of max_iter: 40, perplexity: 2726.8727\n",
      "iteration: 28 of max_iter: 40, perplexity: 2725.4021\n",
      "iteration: 29 of max_iter: 40, perplexity: 2724.1835\n",
      "iteration: 30 of max_iter: 40, perplexity: 2723.1049\n",
      "iteration: 31 of max_iter: 40, perplexity: 2722.1450\n",
      "iteration: 32 of max_iter: 40, perplexity: 2721.2271\n",
      "iteration: 33 of max_iter: 40, perplexity: 2720.3028\n",
      "iteration: 34 of max_iter: 40, perplexity: 2719.4441\n",
      "iteration: 35 of max_iter: 40, perplexity: 2718.6660\n",
      "iteration: 36 of max_iter: 40, perplexity: 2717.9239\n",
      "iteration: 37 of max_iter: 40, perplexity: 2717.1858\n",
      "iteration: 38 of max_iter: 40, perplexity: 2716.4555\n",
      "iteration: 39 of max_iter: 40, perplexity: 2715.8461\n",
      "iteration: 40 of max_iter: 40, perplexity: 2715.2760\n",
      "Topic 0 :\n",
      "[('com', '605.22'), ('www', '484.23'), ('nhttp', '420.22'), ('business', '370.23'), ('money', '308.62'), ('need', '283.11'), ('credit', '265.24'), ('question', '257.76'), ('help', '253.53'), ('want', '253.47'), ('http', '249.22'), ('know', '245.35'), ('10', '241.43'), ('number', '236.90'), ('work', '233.16'), ('company', '222.08'), ('good', '221.81'), ('pay', '220.95'), ('information', '214.38'), ('job', '204.89')]\n",
      "\n",
      "\n",
      "Topic 1 :\n",
      "[('water', '618.10'), ('energy', '306.19'), ('blood', '301.49'), ('light', '296.30'), ('used', '280.21'), ('body', '270.04'), ('nthe', '249.07'), ('does', '247.02'), ('air', '242.72'), ('earth', '225.75'), ('high', '177.90'), ('pressure', '177.29'), ('use', '175.63'), ('gas', '164.00'), ('called', '159.76'), ('mass', '158.29'), ('cells', '157.24'), ('skin', '156.81'), ('cause', '152.05'), ('heat', '144.23')]\n",
      "\n",
      "\n",
      "Topic 2 :\n",
      "[('just', '1109.19'), ('like', '1081.68'), ('don', '892.71'), ('know', '840.33'), ('help', '798.90'), ('good', '749.57'), ('people', '657.41'), ('time', '652.99'), ('want', '652.52'), ('think', '594.64'), ('really', '591.52'), ('need', '575.89'), ('make', '526.77'), ('day', '502.70'), ('work', '477.52'), ('weight', '469.82'), ('way', '463.85'), ('feel', '447.13'), ('try', '389.35'), ('eat', '388.91')]\n",
      "\n",
      "\n",
      "Topic 3 :\n",
      "[('god', '1030.23'), ('people', '965.87'), ('think', '434.51'), ('like', '418.44'), ('just', '415.75'), ('life', '375.65'), ('believe', '372.41'), ('know', '369.92'), ('jesus', '350.25'), ('world', '336.98'), ('bible', '317.21'), ('does', '310.36'), ('say', '289.46'), ('don', '283.55'), ('man', '280.01'), ('religion', '271.25'), ('time', '265.97'), ('question', '253.82'), ('way', '244.07'), ('did', '232.22')]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Junai\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.58      0.51       332\n",
      "           2       0.53      0.32      0.40       314\n",
      "           3       0.54      0.40      0.46       355\n",
      "           7       0.53      0.76      0.62       273\n",
      "\n",
      "    accuracy                           0.50      1274\n",
      "   macro avg       0.51      0.51      0.50      1274\n",
      "weighted avg       0.51      0.50      0.49      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_lda(train_text, test_text, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicksun/anaconda3/envs/py39/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 40, perplexity: 3747.0206\n",
      "iteration: 2 of max_iter: 40, perplexity: 3492.8285\n",
      "iteration: 3 of max_iter: 40, perplexity: 3294.2049\n",
      "iteration: 4 of max_iter: 40, perplexity: 3142.3757\n",
      "iteration: 5 of max_iter: 40, perplexity: 3035.2926\n",
      "iteration: 6 of max_iter: 40, perplexity: 2960.7164\n",
      "iteration: 7 of max_iter: 40, perplexity: 2905.9848\n",
      "iteration: 8 of max_iter: 40, perplexity: 2861.7826\n",
      "iteration: 9 of max_iter: 40, perplexity: 2826.3852\n",
      "iteration: 10 of max_iter: 40, perplexity: 2798.3178\n",
      "iteration: 11 of max_iter: 40, perplexity: 2776.2680\n",
      "iteration: 12 of max_iter: 40, perplexity: 2758.8788\n",
      "iteration: 13 of max_iter: 40, perplexity: 2745.1875\n",
      "iteration: 14 of max_iter: 40, perplexity: 2734.3637\n",
      "iteration: 15 of max_iter: 40, perplexity: 2725.2595\n",
      "iteration: 16 of max_iter: 40, perplexity: 2717.2603\n",
      "iteration: 17 of max_iter: 40, perplexity: 2710.9113\n",
      "iteration: 18 of max_iter: 40, perplexity: 2705.7915\n",
      "iteration: 19 of max_iter: 40, perplexity: 2701.2028\n",
      "iteration: 20 of max_iter: 40, perplexity: 2696.9479\n",
      "iteration: 21 of max_iter: 40, perplexity: 2692.9061\n",
      "iteration: 22 of max_iter: 40, perplexity: 2689.6689\n",
      "iteration: 23 of max_iter: 40, perplexity: 2686.9185\n",
      "iteration: 24 of max_iter: 40, perplexity: 2684.5347\n",
      "iteration: 25 of max_iter: 40, perplexity: 2682.5008\n",
      "iteration: 26 of max_iter: 40, perplexity: 2680.6478\n",
      "iteration: 27 of max_iter: 40, perplexity: 2679.1157\n",
      "iteration: 28 of max_iter: 40, perplexity: 2677.8414\n",
      "iteration: 29 of max_iter: 40, perplexity: 2676.5962\n",
      "iteration: 30 of max_iter: 40, perplexity: 2675.4058\n",
      "iteration: 31 of max_iter: 40, perplexity: 2674.3191\n",
      "iteration: 32 of max_iter: 40, perplexity: 2673.2329\n",
      "iteration: 33 of max_iter: 40, perplexity: 2672.1683\n",
      "iteration: 34 of max_iter: 40, perplexity: 2671.0624\n",
      "iteration: 35 of max_iter: 40, perplexity: 2670.0382\n",
      "iteration: 36 of max_iter: 40, perplexity: 2669.1880\n",
      "iteration: 37 of max_iter: 40, perplexity: 2668.4208\n",
      "iteration: 38 of max_iter: 40, perplexity: 2667.5857\n",
      "iteration: 39 of max_iter: 40, perplexity: 2666.6989\n",
      "iteration: 40 of max_iter: 40, perplexity: 2665.9193\n",
      "Topic 0:\n",
      "[('water', '461.94'), ('nthe', '305.13'), ('energy', '289.43'), ('light', '272.52'), ('earth', '260.50'), ('air', '247.68'), ('10', '232.56'), ('used', '218.01'), ('number', '200.51'), ('does', '198.05'), ('time', '168.76'), ('mass', '165.80'), ('gas', '162.85'), ('like', '158.07'), ('speed', '151.22'), ('force', '147.22'), ('sun', '143.98'), ('heat', '136.61'), ('space', '134.39'), ('answer', '134.01')]\n",
      "\n",
      "\n",
      "Topic 1:\n",
      "[('like', '651.71'), ('help', '615.40'), ('just', '597.85'), ('body', '519.62'), ('weight', '474.70'), ('don', '454.14'), ('good', '437.74'), ('know', '411.42'), ('need', '407.74'), ('day', '387.72'), ('eat', '386.03'), ('time', '381.43'), ('doctor', '361.23'), ('blood', '351.22'), ('really', '333.62'), ('make', '331.50'), ('want', '314.45'), ('does', '287.30'), ('use', '286.97'), ('way', '283.35')]\n",
      "\n",
      "\n",
      "Topic 2:\n",
      "[('people', '1311.95'), ('god', '1021.88'), ('just', '825.18'), ('like', '764.06'), ('think', '750.31'), ('know', '686.30'), ('don', '608.54'), ('life', '563.32'), ('time', '454.74'), ('say', '433.68'), ('believe', '401.57'), ('way', '378.23'), ('want', '378.08'), ('does', '365.99'), ('good', '363.12'), ('really', '361.68'), ('person', '357.69'), ('jesus', '350.25'), ('world', '347.32'), ('did', '339.70')]\n",
      "\n",
      "\n",
      "Topic 3:\n",
      "[('com', '605.23'), ('www', '484.23'), ('nhttp', '420.22'), ('business', '370.24'), ('need', '357.11'), ('work', '355.34'), ('want', '352.55'), ('good', '348.54'), ('money', '344.76'), ('help', '338.73'), ('job', '335.66'), ('know', '295.42'), ('credit', '265.25'), ('pay', '251.57'), ('http', '249.22'), ('like', '228.16'), ('company', '224.93'), ('don', '222.37'), ('make', '220.87'), ('question', '217.78')]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.89      0.79       332\n",
      "           2       0.94      0.64      0.76       314\n",
      "           3       0.84      0.83      0.84       355\n",
      "           7       0.70      0.74      0.72       273\n",
      "\n",
      "    accuracy                           0.78      1274\n",
      "   macro avg       0.80      0.78      0.78      1274\n",
      "weighted avg       0.80      0.78      0.78      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_lda(train_text, test_text, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
